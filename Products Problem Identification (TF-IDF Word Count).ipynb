{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing\n",
    "\n",
    "Brief data exploration and limit our data to subset of reviews in year 2012."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('Reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert the timestamp to the year \n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "data['Time_updated'] = [datetime.fromtimestamp(x) for x in data.Time]\n",
    "data['Year'] = [x.year for x in data.Time_updated]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012    198064\n",
       "2011    163546\n",
       "2010     86092\n",
       "2009     55403\n",
       "2008     34144\n",
       "2007     22358\n",
       "2006      6686\n",
       "2005      1344\n",
       "2004       560\n",
       "2003       133\n",
       "2002        73\n",
       "2000        32\n",
       "2001        13\n",
       "1999         6\n",
       "Name: Year, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Year.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to use the subset of year 2012 to the further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_df = data[data['Year'] == 2012]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_df.to_csv('data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Word Count\n",
    "\n",
    "Define functions to identify the review top words in both high-rating group and low-rating group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_idf_count(df, product='Not Specified', rating='high'):\n",
    "    '''\n",
    "    input format:\n",
    "    - product: default value is 'Not Specified' for all the products; \n",
    "               specify the product by input ProductId, support multiple ProductIds e.g.(AAAAAAAA, BBBBBBBB)\n",
    "    - rating: two values of 'high' (rating score of 4 and 5) and 'low' (rating score between 1 and 3)\n",
    "    '''\n",
    "    # Parameter with product:\n",
    "    \n",
    "    if product=='Not Specified':\n",
    "        df = df\n",
    "    else:\n",
    "        product_list = product.split(\",\")\n",
    "        df = df[df['ProductId'].isin(product_list)]\n",
    "    \n",
    "    #Parameter with rating:\n",
    "    \n",
    "    if rating == 'high':\n",
    "        df = df[df['Score']>=4]\n",
    "    elif rating == 'low':\n",
    "        df = df[df['Score']<=3]\n",
    "    else:\n",
    "        print('Please input high or low for rating parameter')\n",
    "    \n",
    "    # Identify corpus with the data filtered\n",
    "    corpus = list(dict.fromkeys(df['Text'])) \n",
    "    \n",
    "    # Lemmatization:\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    # Function to convert nltk tag to wordnet tag\n",
    "    \n",
    "    def nltk2wn_tag(nltk_tag):\n",
    "        if nltk_tag.startswith('J'):\n",
    "            return wordnet.ADJ\n",
    "        elif nltk_tag.startswith('V'):\n",
    "            return wordnet.VERB\n",
    "        elif nltk_tag.startswith('N'):\n",
    "            return wordnet.NOUN\n",
    "        elif nltk_tag.startswith('R'):\n",
    "            return wordnet.ADV\n",
    "        else:          \n",
    "            return None\n",
    "\n",
    "    def lemmatize_sentence(sentence):\n",
    "        nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))  \n",
    "        wn_tagged = map(lambda x: (x[0], nltk2wn_tag(x[1])), nltk_tagged)\n",
    "        res_words = []\n",
    "        for word, tag in wn_tagged:\n",
    "            if tag is None:            \n",
    "                res_words.append(word)\n",
    "            else:\n",
    "                res_words.append(lemmatizer.lemmatize(word, tag))\n",
    "        return \" \".join(res_words)\n",
    "    \n",
    "    # Get the corpus after lemmatization\n",
    "    \n",
    "    corpus_lem=[]\n",
    "    for review in corpus:\n",
    "        corpus_lem = corpus_lem + [lemmatize_sentence(review)]\n",
    "        \n",
    "    # Regex for the reviews:\n",
    "    \n",
    "    corpus_lem = [s.lower() for s in corpus_lem] # convert to lowercase\n",
    "    \n",
    "    cleanr = re.compile('<.*?>')\n",
    "    corpus_lem = [re.sub(cleanr,'',s) for s in corpus_lem] # remove html tags\n",
    "    \n",
    "    corpus_lem = [str(s).translate(str.maketrans('', '', string.punctuation)) for s in corpus_lem] # remove punc\n",
    "    \n",
    "    stop = stopwords.words()+['like','great','love','good','could','even','would','need']\n",
    "    # add more stopwords\n",
    "    \n",
    "    \n",
    "    # Since the most common food in our products are coffee, cookie, and tea, we can try to generate \n",
    "    # several tags to identify the most common product\n",
    "    \n",
    "    category_tag = 'unknown'\n",
    "    \n",
    "    if product!='Not Specified':\n",
    "        count_coffee = 0\n",
    "        count_tea = 0\n",
    "        count_cookie = 0\n",
    "        count_pets = 0\n",
    "        for review in corpus_lem:\n",
    "            if 'coffee' in review or 'cappuccino' in review or 'latte' in review:\n",
    "                count_coffee+=1\n",
    "            if 'tea' in review:\n",
    "                count_tea+=1\n",
    "            if 'cookie' in review or 'cooky' in review:\n",
    "                count_cookie+=1\n",
    "            if 'dog' in review or 'cat' in review:\n",
    "                count_pets+=1\n",
    "        if count_coffee == max(count_coffee, count_tea, count_cookie, count_pets) and count_coffee/len(corpus_lem)>0.5:\n",
    "            category_tag = 'coffee'\n",
    "            stop = stop+['coffee','cappuccino','latte','taste']\n",
    "        elif count_tea == max(count_coffee, count_tea, count_cookie, count_pets) and count_tea/len(corpus_lem)>0.5:\n",
    "            category_tag = 'tea'\n",
    "            stop = stop+['tea','taste']\n",
    "        elif count_cookie == max(count_coffee, count_tea, count_cookie, count_pets) and count_cookie/len(corpus_lem)>0.5:\n",
    "            category_tag = 'cookie'\n",
    "            stop = stop+['cookie','cooky']\n",
    "        elif count_pets == max(count_coffee, count_tea, count_cookie, count_pets) and count_pets/len(corpus_lem)>0.5:\n",
    "            category_tag = 'pet_foods'\n",
    "            stop = stop+['pet','cat','dog']\n",
    "        else: category_tag = 'others'\n",
    "    \n",
    "    \n",
    "    # Generate TF-IDF word vectorizer\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(ngram_range=(2,3),\n",
    "                             token_pattern=r'\\b[a-zA-Z0-9]{3,}\\b',\n",
    "                             max_df=0.5,\n",
    "                             min_df=1, stop_words=stop)\n",
    "\n",
    "    X = vectorizer.fit_transform(corpus_lem)\n",
    "    terms = vectorizer.get_feature_names()\n",
    "    tf_idf = pd.DataFrame(X.toarray().transpose(), index=terms)\n",
    "    tf_idf = tf_idf.sum(axis=1)\n",
    "    score = pd.DataFrame(tf_idf, columns=[\"score\"])\n",
    "    score[\"term\"] = terms\n",
    "    score.sort_values(by=\"score\", ascending=False, inplace=True)\n",
    "    \n",
    "    print(f'This product or These group products category is {category_tag}')\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This product or These group products category is cookie\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>soft chewy</th>\n",
       "      <td>9.717186</td>\n",
       "      <td>soft chewy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oatmeal raisin</th>\n",
       "      <td>9.671538</td>\n",
       "      <td>oatmeal raisin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quaker soft</th>\n",
       "      <td>8.798857</td>\n",
       "      <td>quaker soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soft baked</th>\n",
       "      <td>8.556104</td>\n",
       "      <td>soft baked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quaker soft baked</th>\n",
       "      <td>7.227345</td>\n",
       "      <td>quaker soft baked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baked oatmeal</th>\n",
       "      <td>6.866643</td>\n",
       "      <td>baked oatmeal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soft baked oatmeal</th>\n",
       "      <td>6.866643</td>\n",
       "      <td>soft baked oatmeal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mom voxbox</th>\n",
       "      <td>6.436194</td>\n",
       "      <td>mom voxbox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year old</th>\n",
       "      <td>4.651767</td>\n",
       "      <td>year old</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>definitely buy</th>\n",
       "      <td>4.586363</td>\n",
       "      <td>definitely buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soft taste</th>\n",
       "      <td>4.437821</td>\n",
       "      <td>soft taste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oatmeal cookies</th>\n",
       "      <td>4.192771</td>\n",
       "      <td>oatmeal cookies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soft bake</th>\n",
       "      <td>4.173181</td>\n",
       "      <td>soft bake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>taste homemade</th>\n",
       "      <td>4.006409</td>\n",
       "      <td>taste homemade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>receive sample</th>\n",
       "      <td>4.001574</td>\n",
       "      <td>receive sample</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>influenster mom</th>\n",
       "      <td>3.919388</td>\n",
       "      <td>influenster mom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soft delicious</th>\n",
       "      <td>3.879461</td>\n",
       "      <td>soft delicious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baked oatmeal cookies</th>\n",
       "      <td>3.406246</td>\n",
       "      <td>baked oatmeal cookies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>really enjoy</th>\n",
       "      <td>3.383656</td>\n",
       "      <td>really enjoy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buy box</th>\n",
       "      <td>3.333918</td>\n",
       "      <td>buy box</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          score                   term\n",
       "soft chewy             9.717186             soft chewy\n",
       "oatmeal raisin         9.671538         oatmeal raisin\n",
       "quaker soft            8.798857            quaker soft\n",
       "soft baked             8.556104             soft baked\n",
       "quaker soft baked      7.227345      quaker soft baked\n",
       "baked oatmeal          6.866643          baked oatmeal\n",
       "soft baked oatmeal     6.866643     soft baked oatmeal\n",
       "mom voxbox             6.436194             mom voxbox\n",
       "year old               4.651767               year old\n",
       "definitely buy         4.586363         definitely buy\n",
       "soft taste             4.437821             soft taste\n",
       "oatmeal cookies        4.192771        oatmeal cookies\n",
       "soft bake              4.173181              soft bake\n",
       "taste homemade         4.006409         taste homemade\n",
       "receive sample         4.001574         receive sample\n",
       "influenster mom        3.919388        influenster mom\n",
       "soft delicious         3.879461         soft delicious\n",
       "baked oatmeal cookies  3.406246  baked oatmeal cookies\n",
       "really enjoy           3.383656           really enjoy\n",
       "buy box                3.333918                buy box"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the function\n",
    "\n",
    "tf_idf_count(sub_df, product = 'B007JFMH8M', rating = 'high').head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This product or These group products category is cookie\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>oatmeal raisin</th>\n",
       "      <td>1.368238</td>\n",
       "      <td>oatmeal raisin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170 calorie</th>\n",
       "      <td>0.841357</td>\n",
       "      <td>170 calorie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soft baked</th>\n",
       "      <td>0.832312</td>\n",
       "      <td>soft baked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>little dry</th>\n",
       "      <td>0.710769</td>\n",
       "      <td>little dry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year old</th>\n",
       "      <td>0.679730</td>\n",
       "      <td>year old</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quaker soft baked</th>\n",
       "      <td>0.657443</td>\n",
       "      <td>quaker soft baked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quaker soft</th>\n",
       "      <td>0.657443</td>\n",
       "      <td>quaker soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soft baked oatmeal</th>\n",
       "      <td>0.617879</td>\n",
       "      <td>soft baked oatmeal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baked oatmeal</th>\n",
       "      <td>0.617879</td>\n",
       "      <td>baked oatmeal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>individually wrap</th>\n",
       "      <td>0.586720</td>\n",
       "      <td>individually wrap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soft moist</th>\n",
       "      <td>0.557801</td>\n",
       "      <td>soft moist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glass milk</th>\n",
       "      <td>0.552848</td>\n",
       "      <td>glass milk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chocolate chip</th>\n",
       "      <td>0.541141</td>\n",
       "      <td>chocolate chip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quaker oatmeal</th>\n",
       "      <td>0.531884</td>\n",
       "      <td>quaker oatmeal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tasty soft</th>\n",
       "      <td>0.524156</td>\n",
       "      <td>tasty soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soft chewy</th>\n",
       "      <td>0.487079</td>\n",
       "      <td>soft chewy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>say make</th>\n",
       "      <td>0.447214</td>\n",
       "      <td>say make</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>make self quaker</th>\n",
       "      <td>0.447214</td>\n",
       "      <td>make self quaker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>say make self</th>\n",
       "      <td>0.447214</td>\n",
       "      <td>say make self</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self quaker</th>\n",
       "      <td>0.447214</td>\n",
       "      <td>self quaker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       score                term\n",
       "oatmeal raisin      1.368238      oatmeal raisin\n",
       "170 calorie         0.841357         170 calorie\n",
       "soft baked          0.832312          soft baked\n",
       "little dry          0.710769          little dry\n",
       "year old            0.679730            year old\n",
       "quaker soft baked   0.657443   quaker soft baked\n",
       "quaker soft         0.657443         quaker soft\n",
       "soft baked oatmeal  0.617879  soft baked oatmeal\n",
       "baked oatmeal       0.617879       baked oatmeal\n",
       "individually wrap   0.586720   individually wrap\n",
       "soft moist          0.557801          soft moist\n",
       "glass milk          0.552848          glass milk\n",
       "chocolate chip      0.541141      chocolate chip\n",
       "quaker oatmeal      0.531884      quaker oatmeal\n",
       "tasty soft          0.524156          tasty soft\n",
       "soft chewy          0.487079          soft chewy\n",
       "say make            0.447214            say make\n",
       "make self quaker    0.447214    make self quaker\n",
       "say make self       0.447214       say make self\n",
       "self quaker         0.447214         self quaker"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_count(sub_df, product = 'B007JFMH8M', rating = 'low').head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B007JFMH8M    913\n",
       "B006MONQMC    491\n",
       "B002IEZJMA    483\n",
       "B002IEVJRY    483\n",
       "B007Y59HVM    480\n",
       "B005ZBZLT4    480\n",
       "B001VJ0B0I    479\n",
       "B002LANN56    460\n",
       "B0041NYV8E    450\n",
       "B005K4Q37A    412\n",
       "B005K4Q34S    412\n",
       "B005K4Q1YA    412\n",
       "B005K4Q4LK    412\n",
       "B003B3OOPA    401\n",
       "B005HG9ET0    386\n",
       "Name: ProductId, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df.ProductId.value_counts().head(15) # get the number of reviews for each product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This product or These group products category is coffee\n"
     ]
    }
   ],
   "source": [
    "neg_review = tf_idf_count(sub_df, product = 'B005K4Q4LK', rating = 'low') \n",
    "# randomly select a product and output to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This product or These group products category is coffee\n"
     ]
    }
   ],
   "source": [
    "pos_review = tf_idf_count(sub_df, product = 'B005K4Q4LK', rating = 'high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg_review.to_csv('neg_review.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_review.to_csv('pos_review.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
